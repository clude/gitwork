http://blog.csdn.net/u011491148/article/details/45749807    利用Phoenix为HBase创建二级索引
其核心思想是保证索引表和主表在同一个region server上。详见：https://github.com/Huawei-Hadoop/hindex    http://www.dengchuanhua.com/167.html   http://www.thebigdata.cn/upload/2013-10/13101415173453.pdf
HBase在0.92之后引入了coprocessors，提供了一系列的钩子，让我们能够轻易实现访问控制和二级索引的特性。   http://www.dengchuanhua.com/149.html  
在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位+机器ID 10位+毫秒内序列12位。
该项目地址为：https://github.com/twitter/snowflake是用Scala实现的。     http://www.dengchuanhua.com/132.html
 
http://my.oschina.net/leejun2005/blog/543048?fromerr=4jqPCSkc  HBase 原理、设计与优化实践
http://www.bitstech.net/2015/12/04/hbase-optmization/?utm_source=tuicool&utm_medium=referral  HBase优化实战
比较像MongoDB的sharding模式，能根据键值的大小，把数据分布到不同的存储节点上，MongoDB根据configserver来定位数据落在哪个分区上，HBase通过访问Zookeeper来获取-ROOT-表所在地址，通过-ROOT-表得到相应.META.表信息，从而获取数据存储的region位置。
http://my.oschina.net/leejun2005/blog/92776  HBase性能优化方法总结


http://www.rowkey.me/blog/2015/06/10/hbase-about/
http://songlee24.github.io/2015/07/24/hbase-introduction/


进入命令：hbase shell
查看有多少表：list
查看表的结构：describe 'DEVICE'
查看表的数据：scan 'DEVICE'
查看某一行：get 'DEVICE',''
查看某列族的所有数据： scan 'DEVICE',{COLUMNS => 'course'}
删除表：drop 'testtable'   （删除表之前先要禁用表，命令disable 'testtable'）
启用和禁用表： enable 'testtable' 和disable 'testtable'
bin/hbase hbck  (检查)
bin/hbase hbck -fix  （修复）
bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --peer.adr=zookeeper1,zookeeper2,zookeeper3:/hbase 'testtable'
bin/hbase org.apache.hadoop.hbase.mapreduce.Export testtable /user/testtable [versions] [starttime] [stoptime]
bin/hbase org.apache.hadoop.hbase.mapreduce.Import testtable  /user/testtable
首先拷贝hdfs文件，如bin/hadoop distcp hdfs://srcnamenode:9000/hbase/testtable/ hdfs://distnamenode:9000/hbase/testtable/
然后在目的hbase上执行bin/hbase org.jruby.Main bin/add_table.rb /hbase/testtable


http://www.oschina.net/news/69616/review-and-development-of-apache-hbase     Apache HBase 2015 年发展回顾与未来展望
https://github.com/yahoo/omid    Omid 项目来自 Yahoo，用于给使用快照隔离的键值存储提供事务支持。    http://tephra.io/
https://github.com/HuaweiBigData/astro    Spark SQL on HBase package 项目又名 Astro，端到端整合了 Spark，Spark SQL和HBase的能力

https://github.com/ndimiduk/hbase-1.0-api-examples  hbase 1.0
http://wuchong.me/blog/2015/04/06/spark-on-hbase-new-api/
http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/  metrics

http://phoenix.apache.org/   Apache Phoenix is a relational database layer over HBase delivered as a client-embedded JDBC driver targeting low latency queries over HBase data. 
针对HBase上SQL解决方案，目前社区内比较热门的有Cloudera的Impala，Horntworks的Drill，以及Hive

http://blog.csdn.net/yaoyasong/article/details/39400829  应用Flume+HBase采集和存储日志数据
http://m.csdn.net/article/2015-02-10/2823915  结合美团下单率预测详解机器学习中的数据清洗与特征处理
http://m.csdn.net/article/a/2015-01-29/15822434


http://blog.csdn.net/u010967382/article/details/37878701?utm_source=tuicool  HBase基本数据操作详解
http://xstarcd.github.io/wiki/Cloud/hbase_tips.html   hbase日常操作收集

docker
http://bigdata-blog.net/2014/10/14/hfile%E5%92%8Chlog%E7%9A%84%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/  HFile和HLog的回收机制
http://bigdata-blog.net/2014/12/03/%E5%8D%81%E5%88%86%E9%92%9F%E5%BC%80%E5%8F%91hbase%E5%BA%94%E7%94%A8/#more-216   十分钟开发HBase应用
docker run -d --net=host tobegit3hub/standalone-hbase-0.94
docker run -i -t --net=host tobegit3hub/smoke-hbase
https://github.com/nerdammer/dockers
docker run -it --rm --name dockerbase-devbase-hbase dockerbase/devbase-hbase
http://lifuzu.com/blog/2015/02/03/getting-familiar-with-hbase-on-dockerbase/
docker run -it --rm --name dockerbase-devbase-hadoop dockerbase/devbase-hadoop
http://lifuzu.com/blog/2015/02/03/playing-with-hadoop-on-dockerbase/


coprocessor
Using HBase coprocessors, custom features such as secondary indexing, complex filtering and access control features can be developed.
RegionObserver provides a hook for data manipulation operations such as Get, Put, Delete, Scan, and so on.The configuration property, hbase.coprocessor.region.classes, can be set to register the region observer.
RegionServerObserver: This observer provides the pre and post hooks for the merge, commits, and rollback operations and runs within the context of the HBase region server. This coprocessor can be registered using the hbase.coprocessor.regionserver.classes configuration property.
WALObserver: This observer provides hooks for the write-ahead log (WAL) and support for the pre and post WAL write events. can be registered by setting the hbase.coprocessor.wal.classes
configuration property.
MasterObserver: This observer provides hooks for data definition type operations such as table creation, deletion, schema modification, and so on. The MasterObserver coprocessor runs within the context of HBase Master and can be registered by setting the hbase.coprocessor.master.classes configuration property.


hbase.replication  add_peer   start_replication   异步集群之间复制
<name>hbase.client.scanner.caching</name>  
SASL  hbase.security.authentication    hadoop.security.authentication
Region迁移的时候不能简单开启自动balance，因为balance主要的问题是不会根据表来进行balance，HBase的自动balance只会根据每个RegionServer上的Region数量来进行balance，
可以通过切分的方法生成多个小region后均匀分布(注意：region切分会触发major compact操作，会带来较大的I/O请求，请务必在业务低峰期进行)
一般地，HBase客户端的写入到RegionServer下某个region的memstore后就返回，除了网络外，其他都是内存操作

在HBase中，数据在更新时首先写入WAL 日志(HLog)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时， 系统会在zookeeper中记录一个redo point，表示这个时刻之前的变更已经持久化了(minor compact)。
StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact)，将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行分割(split)，等分为两个StoreFile。



HBase 0.92引入了Coprocessor这项特性，可以很方便地在RegionServer端实现各类聚集操作，通过AggregationClient#rowCount这个接口就可以相对高效地统计表的行数了。
Coprocessor提供了Observer和Endpoint两项特性，前者允许通过重写函数在RegionServer端注入用户代码，后者则相当于数据库中的触发器
http://bigdata-blog.net/2013/11/15/hbase%E8%A1%8C%E6%95%B0%E7%BB%9F%E8%AE%A1/
<name>hbase.coprocessor.user.region.classes</name>
<value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
hbase> alter 'mytable', METHOD => 'table_att','coprocessor'=>'|org.apache.hadoop.hbase.coprocessor.AggregateImplementation||'
http://michaelmorello.blogspot.tw/2012/01/row-count-hbase-aggregation-example.html


如果HBase单个节点出现故障，Zookeeper会通知master主进程，master会将HLog日志进行拆分，分发到其他RegionServer上进行数据恢复。HBase对于单点故障的容错能力还是不错的
HBase 0.90以后开始支持Replication机制，该机制设计的主导思想是基于操作日志(put/get/delete)做数据同步，这点很像MySQL基于Binary Log做statement-based replication
客户端的put/delete操作会被RegionServer写入本地的HLog中去，与此同时每个RegionServer会将Hlog放入对应znode上的Replication队列，HBase集群会有一个独立的线程，根据固定大小的buffer值，将HLog内容推送到Slave Cluster集群中的某个RegionServer上(当前版本只支持单个Slave Cluster复制)，并在将当前复制的偏移量保存在ZooKeeper上，整个过程是异步完成的。
http://www.infoq.com/cn/articles/lp-hbase-data-disaster-recovery


通过Cloudera Manager安装CDH   http://blog.javachen.com/2013/06/24/install-cdh-by-cloudera-manager/
http://www.micmiu.com/bigdata/hbase/hbase-setup-standalone/   hbase安装
HBASE_MANAGES_ZK=false
hbase.zookeeper.quorum


Scan(byte[] startRow, Filter filter)
Scan(byte[] startRow, byte[] stopRow)
Scan setFilter(Filter filter)

ResultScanner类
scan并不是一次RPC中把所有结果都返回给client，而是以row为单位返回的。
Result next() throws IOException
Result[] next(int nbRows) throws IOException
void close()（finally里面关闭）

public void setBatch(int batch) ：为设置获取记录的列个数，默认无限制，也就是返回所有的列
public void setCaching(int caching)：每次从服务器端读取的行数，默认为配置文件中设置的值

ColumnPrefixFilter用于指定列名前缀值相等  
MultipleColumnPrefixFilter和ColumnPrefixFilter行为差不多，但可以指定多个前缀。  
QualifierFilter是基于列名的过滤器

zookeeper
http://supben.iteye.com/blog/2094077  TestingServer 模拟单点， TestingCluster模拟集群。
http://ifeve.com/zookeeper-curato-framework/



http://blog.csdn.net/hengyunabc/article/details/41146115   日志收集分析
http://koven2049.iteye.com/blog/983633
http://www.ngdata.com/the-hbase-side-effect-processor-and-hbase-replication-monitoring/
HBase的Relication机制，其实和Mysql的同步机制很像，HBase的每个Region Server都会有WAL Log，当Put/Delete时，都会先写入到WAL Log里。然后后台有线程会把WAL Log随机发给Slave的Region Server。而Slave的Region Server会在zookeeper上记录自己同步到的位置。  

 MVCC(Multi-Version Concurrent Control),即多版本并发控制协议,广泛使用于数据库系统


http://blog.csdn.net/xiejx618/article/details/21201007 org.springframework.mock.web.MockMultipartFile
http://jinnianshilongnian.iteye.com/blog/1469524   spring test
http://www.iteedu.com/webtech/j2ee/spring25cn/ch08s03.php  SimpleJdbcTestUtils
http://blog.csdn.net/moxiaomomo/article/details/16817497   HBaseTestingUtility
http://m.blog.csdn.net/blog/aaa1117a8w5s6d/17761511
http://blog.csdn.net/feihong247/article/details/7828143
http://docs.spring.io/spring/docs/current/spring-framework-reference/html/testing.html
http://www.ibm.com/developerworks/cn/java/j-lo-springunitest/
http://blog.jdwyah.com/2013/02/mock-hbase-for-unit-testing.html
http://dirlt.com/hadoop.html
http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/

zookeeper
PathChildrenCache用来监控一个ZNode的子节点. 当一个子节点增加， 更新，删除时， Path Cache会改变它的状态， 会包含最新的子节点， 子节点的数据和状态。 
NodeCache用来监控一个ZNode. 当节点的数据修改或者删除时，Node Cache能更新它的状态包含最新的改变。
TreeCache这种类型的即可以监控节点的状态，还监控节点的子节点的状态， 类似上面两种cache的组合。 这也就是Tree的概念。 它监控整个树中节点的状态。
http://ifeve.com/zookeeper-path-cache/
http://ifeve.com/zookeeper-barrier/
http://macrochen.iteye.com/blog/1366136

hadoop
http://www.cnblogs.com/vigiles/p/3643489.html?utm_source=tuicool
http://blog.csdn.net/hadoop_/article/details/11538201?utm_source=tuicool
http://blog.csdn.net/yeruby/article/details/19995367
http://wuchong.me/blog/2015/04/06/spark-on-hbase-new-api/
HBase 实现了 TableInputFormatBase 类，该类提供了对表数据的大部分操作，其子类 TableInputFormat 则提供了完整的实现，用于处理表数据并生成键值对。
HBase 实现了 TableMapper 类和 TableReducer 类   HBase 实现的 TableOutputFormat 将输出的<key,value>对写到指定的 HBase 表中，该类不会对 WAL（Write-Ahead  Log）进行操作
http://www.jianshu.com/p/722a75d2b2bd
