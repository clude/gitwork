kafka
http://www.oneapm.com/ci/kafka.html  jmx监控
镜像地址: testregistry.dataman.io/centos7/jdk7-scala2.11-kafka0.8.22
Yahoo 构建了一个基于 Web 的管理工具，称为 Kafka Manager
镜像地址: testregistry.dataman.io/centos7/jdk8-kafka-0.8.x-manager
http://blog.dataman-inc.com/20151218-kafka-shurenyun/
https://docs.qingcloud.com/guide/queue.html#id8  常用配置项
http://colobu.com/2014/08/06/kafka-quickstart/
https://www.mapr.com/blog/getting-started-sample-programs-apache-kafka-09
http://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0.9-consumer-client
http://colobu.com/2015/12/04/Kafka-0-9-is-released/  安全 Kafka Connect 新的Consumer


http://bupt.io/?p=765
http://www.aboutyun.com/thread-9906-1-1.html   kafka客户端开发-java
http://blog.csdn.net/honglei915/article/details/37563647
http://doc.okbase.net/QING____/archive/19447.html
http://news.csdn.net/article_preview.html?preview=1&reload=1&arcid=2825342  七牛是如何搞定每天500亿条日志的  Flume、Kafka、Spark以及Streaming
http://www.open-open.com/lib/view/open1412991579999.html   kafka java 生产消费程序demo示例
http://www.weixinyidu.com/n_366292
http://www.cnblogs.com/oftenlin/p/4045924.html
http://blog.csdn.net/honglei915/article/details/37564329  Kafka运行环境
http://blog.csdn.net/honglei915/article/details/37564521  简单介绍
http://blog.csdn.net/honglei915/article/details/37932819
http://my.oschina.net/cloudcoder/blog/299215   Kafka JAVA客户端代码示例
http://www.iteblog.com/archives/1084   Apache Kafka监控之Kafka Web Console
http://www.centoscn.com/CentosServer/cluster/2015/0312/4863.html  Centos安装Kafka集群
http://www.cnblogs.com/oftenlin/p/4047504.html   kafka 集群安装与安装测试
Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。
Offset：kafka的存储文件都是按照offset.kafka来命名
物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件
Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据
server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定
http://www.infoq.com/cn/author/%E9%83%AD%E4%BF%8A#文章
broker change是由BrokerChangeListener监听类，监听/brokers/ids下得brokerid
多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over
对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费  Kafka保证的是稳定状态下每一个Consumer实例只会消费某一个或多个特定 Partition的数据，而某个Partition的数据只会被某一个特定的Consumer实例所消费。也就是说Kafka对消息的分配是以 Partition为单位分配的，而非以每一条消息作为分配单元。这样设计的劣势是无法保证同一个Consumer Group里的Consumer均匀消费数据
http://sookocheff.com/post/kafka/kafka-in-a-nutshell/
http://www.tuicool.com/articles/R3A3Y3    Producer端使用zookeeper用来"发现"broker列表,以及和Topic下每个partition leader建立socket连接并发送消息.
http://www.infoq.com/cn/articles/kafka-analysis-part-4   Kafka设计解析（四）：Kafka Consumer解析
http://www.infoq.com/cn/author/%E9%83%AD%E4%BF%8A#文章
https://github.com/wurstmeister/storm-kafka-0.8-plus

http://www.michael-noll.com/blog/2014/05/27/kafka-storm-integration-example-tutorial/
https://github.com/linkedin/gobblin/wiki/Kafka-HDFS-Ingestion  导入hdfs
https://github.com/linkedin/camus


http://ju.outofmemory.cn/entry/205022
http://ju.outofmemory.cn/entry/119495
http://blog.csdn.net/kisimple/article/details/42342459
https://github.com/apache/zookeeper/blob/trunk/src/java/main/org/apache/zookeeper/server/SnapshotFormatter.java
每一个topic会有几个partition目录，partition下面的就是message文件，称为log文件，log文件是以它所保存的第一条message的offset命名。每一条message就是一个log entry
Kafka使用Yammer Metrics来报告服务端和客户端的Metric信息。

 
http://queues.io/
https://github.com/huanghua581/notes/blob/master/PHP/%E5%B8%B8%E8%A7%81%E5%BC%80%E6%BA%90%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F.md

https://github.com/antirez/disque  alpha
 
replication factor控制有多少个server将会复制各条被写入Topic的消息。如果该值为3，那么可以有2台server停止工作的情况下，消费端以访问到消息。我们建议你设置该值为2或者3，这样就可以在重启服务时而不影响消费端消费数据。
默认情况下是不能删除Topic，如果需要删除Topic的话，请在配置文件里设置如下属性delete.topic.enable=true

Kafka备份的数据单元是partition，每个partition有一个leader和若干follower。replica的总数取决于所有broker的数量（包括leader）。broker作为工作单元（服务器），一个partition可以有多个broker，反之一个broker下也有多个partition（partition可能是不同topic的）。
follower同步从leader同步数据的方式与正常的Consumer相同，从leader读取数据然后存入自己的log队列。一条新的数据进入后，在所有“in sync”的replica成功将其放入自己的队列后，这条数据才能被正常的Consumer读取。这个过程在Kafka中被称为“committed”。
而“in sync”是指，leader会维护一个满足以下两个条件的replica节点集合：节点必须能与zookeeper保持正常通信   它必须保证从leader同步的数据不能掉队太多
http://www.xmuyoo.com/2015/10/16/KafkaReplication/

Kafka默认的消息大小为1000012,参数的名称为message.max.bytes.  但是对于topic来说，这个参数的名称却叫max.message.bytes，和前面的参数的名称很容易弄混。
http://colobu.com/2015/05/14/one-config-parameter-in-kafka/


activemq
http://blog.csdn.net/a19881029/article/details/35279677 
http://blog.csdn.net/johnny901114/article/details/8898727
http://www.cnblogs.com/rongfengliang/articles/3420652.html
http://www.hivemq.com/wp-content/uploads/hivemq_websocket_demo_app.html


RocketMQ的前身是Metaq，当Metaq3.0发布时，产品名称改为RocketMQ
https://github.com/alibaba/RocketMQ/wiki/rmq_vs_kafka  比较
http://blog.csdn.net/a19881029/article/details/34446629
http://my.oschina.net/firxiao/blog/314834   RocketMQ 消息队列简单部署
http://my.oschina.net/cloudcoder/blog/200741   	RocketMQ：一个纯java的开源消息中间件--开发测试环境搭建
http://blog.csdn.net/a19881029/article/details/34446629
 

metaq 的zk目录结构在 com.taobao.metamorphosis.utils.MetaZookeeper 这个Meta与zookeeper交互的辅助类中

zk
http://blog.csdn.net/xiaolang85/article/details/13021339
http://www.cnblogs.com/ggjucheng/p/3352591.html
http://www.coder4.com/archives/3122