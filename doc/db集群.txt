http://blog.csdn.net/lifaming15/article/details/44340101
http://blog.csdn.net/dreamcode/article/details/44307377
http://www.csdn.net/article/2015-07-16/2825228
http://download.csdn.net/detail/dreamcode/8933053
MyCAT的诞生，要从其前身Amoeba和Cobar说起。
Amoeba（变形虫）项目，该开源框架于2008年开始发布一款 Amoeba for Mysql软件。这个软件致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间，对客户端透明。具有负载均衡、高可用性、SQL过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。 
阿里巴巴于2012年6月19日，正式对外开源的数据库中间件Cobar，前身是早已经开源的Amoeba，不过其作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar。
MyCAT使用MySQL的通讯协议模拟成一个MySQL服务器，并建立了完整的Schema（数据库）、Table （数据表）、User（用户）的逻辑模型，并将这套逻辑模型映射到后端的存储节点DataNode（MySQL Instance）上的真实物理库中
当MyCAT收到一个客户端发送的SQL请求时，会先对SQL进行语法分析和检查，分析的结果用于SQL路由，SQL路由策略支持传统的基于表格的分片字段方式进行分片，也支持独有的基于数据库E-R关系的分片策略，对于路由到多个数据节点（DataNode）的SQL，则会对收到的数据集进行“归并”然后输出到客户端。

MYCAT_HOME/conf/schema.xml中定义逻辑库，表、分片节点等内容；
MYCAT_HOME/conf/rule.xml中定义分片规则；
MYCAT_HOME/conf/server.xml中定义用户以及系统相关变量，如端口等。

http://www.csdn.net/article/2015-06-02/2824824  tdsql
http://bluereader.org/article/30433169
http://wenku.baidu.com/link?url=ZjdARG02YMFdjtC4mZUOomJrH4qaW1TjVhZBU3UvQ0xLyvBrlDcbNL6Ebt5e525WcLI0DzSk8xcDNw0OmhqSpWlX_UdGH1hYI0bkETyphuO
START SLAVE  http://hunng.com/2014/06/18/centos-mysql-master-slave-replication/

MariaDB Galera Cluster
http://code.oneapm.com/database/2015/07/02/mariadb-galera-cluster/
Galera是一个MySQL(也支持MariaDB，Percona)的同步多主集群软件，目前只支持InnoDB引擎。
http://www.oschina.net/translate/from-mysql-mmm-to-mariadb-galera-cluster-a-high-availability-makeover
对于标准版的MySQL，对master的写操作被记录于一个二进制的日志。Slave会在之后复制二进制日志中的查询。查询在写服务器上运行与在其它节点上运行时刻之间，总是会有一个延迟。它是异步的。
MySQL异步复制有下面的问题：slave服务器的数据集总是落后于master服务器。MySQL复制很慢――它从二进制日志回访事务。
对于Galera,事务是在它们被提交之前被所有节点确认。如果一个事务在一个节点失败了，那个节点将立刻从群集中移除。换句话说，Galera主从复制是同步的。
http://www.tuicool.com/articles/zmm6ra


http://blog.csdn.net/dreamcode/article/details/45740347
建议采用如下的部署方式：Redis Master上不做持久化保证读写性能，Slave上同时开启RDB（快照）和AOF，保证数据的安全性。当 Redis启动时，程序会优先使用 AOF 文件来恢复数据集，因为AOF文件所保存的数据通常是最完整的。
slaveof conf配置文件 slaveof 192.168.1.1 6379    masterauth redis123
redis的slave默认变得不再接受写操作 #slave-read-only yes
redis 127.0.0.1:6379> SLAVEOF 192.168.1.100 6379
redis 127.0.0.1:6379> SLAVEOF no one
如果当前服务器已经是某个主服务器(master server)的从属服务器，那么执行 SLAVEOF host port 将使当前服务器停止对旧主服务器的同步，丢弃旧数据集，转而开始对新主服务器进行同步。
查看同步的状态，可以使用info命令  redis-cli -h 192.168.9.18 info Replication
可以在master禁用数据持久化，只需要注释掉master 配置文件中的所有save配置，然后只在slave上配置数据持久化    appendonly no #禁用AOF
RDB Redis forks.子进程开始将数据写到临时RDB文件中。当子进程完成写RDB文件，用新文件替换老文件。这种方式可以使Redis使用copy-on-write技术。快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。
测试是否已启动 redis-cli ping
强制刷新数据到磁盘 redis-cli -p 6379 save

Codis 2.0 发布，Redis 集群解决方案 由四部分组成:Codis Proxy   (codis-proxy)  Codis Manager (codis-config)  Codis Redis   (codis-server) ZooKeeper
codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议,可以部署多个 codis-proxy, codis-proxy 本身是无状态的.
codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard
codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.13 开发, 加入了 slot 的支持和原子的数据迁移指令
Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy.
正确的步骤在codis/sample/usage.md里，作者都写好了启动脚本   Codis会根据我们在config.ini中配置的product_name作为ZooKeeper中的路径。
Redis本身的replication模型是主从异步复制，在master上写成功后，在slave上是否能读到这个数据是没有保证的，
hashtag(用花括号扩住计算hash的区域)：{uid1}age，{uid1}sex，{uid1}name，这样就保证这些key分布在同一个机器上。这个是twemproxy引入的一个语法    
在生产环境中，我建议master的机器不要开bgsave，也不要轻易的执行save命令，数据的备份尽量放在slave上操作
http://www.open-open.com/lib/view/open1436360508098.html  Codis作者黄东旭细说分布式Redis架构设计和踩过的那些坑们    通过presharding把数据在概念上分成1024个slot（hash算法是crc32(key)%1024），然后通过proxy将不同的key的请求转发到不同的机器上，数据的副本还是通过Redis本身保证
http://blog.csdn.net/dc_726/article/details/47052607
http://blog.csdn.net/dc_726/article/details/46746015
http://blog.csdn.net/dc_726/article/details/48832405   分布式一致性协议Raft原理与实例
http://thesecretlivesofdata.com/raft/   动画raft
http://blog.csdn.net/dc_726/article/details/46475633   Apache Curator入门实战
http://blog.csdn.net/dc_726/article/details/46565241    Java程序员的Golang入门指南
http://blog.csdn.net/dc_726/article/details/46745947
http://blog.csdn.net/dc_726/article/details/46565257  用Netty解析Redis网络协议
http://blog.csdn.net/dc_726/article/details/47355959  负载均衡LVS(DR模式)安装实战

闪存文件系统，包括JFFS2和Yaffs
http://www.programmer.com.cn/14015/    从Google Spanner漫谈分布式存储与数据库技术

etcd 使用Go语言编写部署简单；使用HTTP作为接口使用简单；使用Raft算法保证强一致性让用户易于理解。 WAL：Write Ahead Log（预写式日志）
http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle/


InfluxDB
http://www.ttlsa.com/monitor-safe/monitor/distributed-time-series-database-influxdb/


tidb
http://www.open-open.com/lib/view/open1441538618194.html



elasticsearch集群  
http://www.cnblogs.com/dennisit/p/4133131.html
http://www.cnblogs.com/luxiaoxun/p/4869509.html?utm_source=tuicool&utm_medium=referral
http://www.codeweblog.com/elasticsearch-%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bmaster%E9%80%89%E4%B8%BE/
http://www.chepoo.com/elasticsearch-zen-discovery.html
https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html
elasticsearch集群发现机制有两种：Zen Discovery和 EC2 discovery。EC2：亚马逊弹性计算云。Zen Discovery作用就相当于solrcloud中的zookeeper
discovery.zen.ping_timeout（默认值是3秒）：默认情况下，一个节点会认为，如果master节点在3秒之内没有应答，那么这个节点就是死掉了，而增加这个值，会增加节点等待响应的时间，从一定程度上会减少误判。
discovery.zen.minimum_master_nodes（默认是1）：这个参数控制的是，一个节点需要看到的具有master节点资格的最小数量，然后才能在集群中做操作。官方的推荐值是(N/2)+1，其中N是具有master资格的节点的数量
http://www.qixing318.com/article/the-concept-of-elasticsearch.html
discovery.zen代表 elasticsearch 的自动节点发现机制，而且 elasticsearch还是一个基于 p2p 的系统。
首先它它会通过以广播的方式去寻找存在的节点，然后再通过多播协议来进行节点之间的通信，于此同时也支持点对点的交互操作。

Marvel免费了(仅限管理一个集群，多集群仍需要收费)，Sense也开源了
一个集群则会包含拥有相同cluster.name的一个或者多个节点，这些节点共同工作来完成数据共享和负载分担。
集群中的一个节点会被选为主节点(Master Node)，它负责管理整个集群的变化，如创建或者删除一个索引(Index)，向集群中添加或者删除节点。主节点并不需要参与到文档级别的变化或者搜索中，这意味着虽然只有一个主节点，但它并不会随着流量的增加而成为瓶颈。
GET /_cluster/health  # Retrieve the cluster health
一个分片可以是主分片(Primary Shard)或者副本分片(Replica Shard)。索引中的每份文档都属于一个主分片，所以主分片的数量就决定了你的索引能够存储的最大数据量。
一个副本分片则只是一个主分片的拷贝。副本用来提供数据冗余，用来保护数据在发生硬件故障是不会丢失，同时也能够处理像搜索和获取文档这样的读请求。主分片的数量在索引建立之初就会被确定下来，而副本分片的数量则可以在任何时候被更改。
http://blog.csdn.net/quicknet/article/details/42117891
http://blog.csdn.net/quicknet/article/details/42078747
ElasticSearch是建立在一组Lucene索引基础上的抽象层， 它的每一个 shard（无论primary 和 replica）都是一个完整和独立的Lucene索引实例。说白了，也就是在一组Lucene索引上建了 "another level of indirection"，这层indirection带来的好处就是 : 分布式、可扩展和强容错的索引集群系统。其实，Lucene索引本身也是一层indirection， 真正的索引内容是存储在被称为segment单元中。一个Lucene索引由多个segment组成，segment是immutable的，也就是创建后不能再修改的，各种索引内容的缓存也都是基于每个segment的。
所以，当ElasticSearch收到一个为文档建立索引的请求时，它首先要做出的决定就是要在哪一个shard上对文档进行索引并保存结果。在具体实现上，ElasticSearch采用的是djb2 哈希算法对要索引文档的指定（或者默认的）key进行哈希，得到哈希结果后取模上（mod） ElasticSearch索引shard数目 n

kafka集群
MirrorMaker:一个用来在不同的Kafka集群之间移动数据的开源项目。
http://www.infoq.com/cn/articles/kafka-analysis-part-2
http://edu.51cto.com/index.php?do=lesson&id=45897  kafka集群部署在zk里的存储结构
http://blog.csdn.net/lizhitao/article/details/23744675?utm_source=tuicool&utm_medium=referral    apache kafka系列之在zookeeper中存储结构
http://blog.csdn.net/lizhitao/article/details/38442733#comments
http://blog.csdn.net/lizhitao/article/details/38439769
http://blog.csdn.net/lizhitao/article/details/39499283#comments
http://blog.csdn.net/lizhitao/article/details/42180265 kafka server部署配置优化
http://www.aboutyun.com/thread-9341-1-1.html

http://m.oschina.net/blog/304818
http://www.infoq.com/cn/articles/kafka-analysis-part-1/
http://debugo.com/kafka-params/